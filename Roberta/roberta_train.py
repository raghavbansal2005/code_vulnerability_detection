import json
import os
from sklearn.model_selection import train_test_split
import numpy as np
import torchmetrics
import torch
from torch.utils.data import DataLoader
from transformers import RobertaTokenizer, RobertaForSequenceClassification
import torchmetrics
from torch.optim import AdamW
import pandas as pd
from pynvml import *
from transformers import AutoTokenizer
import wandb

def print_gpu_utilization():
    nvmlInit()
    handle = nvmlDeviceGetHandleByIndex(0)
    info = nvmlDeviceGetMemoryInfo(handle)
    print(f"GPU memory occupied: {info.used//1024**2} MB.")


def print_summary(result):
    print(f"Time: {result.metrics['train_runtime']:.2f}")
    print(f"Samples/second: {result.metrics['train_samples_per_second']:.2f}")
    print_gpu_utilization()



class JdDataSet(torch.utils.data.Dataset):
    def __init__(self, encodings, labels):
        self.encodings = encodings
        self.labels = labels

    def __getitem__(self, idx):
        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}
        item['labels'] = torch.tensor(self.labels[idx])
        return item

    def __len__(self):
        return len(self.labels)



if __name__ == "__main__":

    LEARNING_RATE = 5e-5
    BATCH_SIZE = 4
    EVAL_BATCH_SIZE = 4
    LOG_INTERVAL = 40

    config = dict (
    learning_rate = LEARNING_RATE,
    batch_size = BATCH_SIZE,
    eval_batch_size = EVAL_BATCH_SIZE,
    log_interval = LOG_INTERVAL
    )

    wandb.init(
    project="Vulnerability Detection Multi Class",
    name = "ROBERTA",
    config=config,
    )


    def cycle(iterable):
        while True:
            for x in iterable:
                yield x

    def read_jd_split(file_path):
        df = pd.read_pickle(file_path)
        texts = df["file_contents"].to_list()
        labels = df["vulnerability_id"].to_list()

        return texts, labels

    train_texts, train_labels = read_jd_split("./roberta_train_data_multi_class.pkl")
    test_texts, test_labels = read_jd_split("./roberta_test_data_multi_class.pkl")

    train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)

    tokenizer = AutoTokenizer.from_pretrained("microsoft/codebert-base")

    train_encodings = tokenizer(train_texts, truncation=True, padding=True)
    val_encodings = tokenizer(val_texts, truncation=True, padding=True)
    test_encodings = tokenizer(test_texts, truncation=True, padding=True)

    train_dataset = JdDataSet(train_encodings, train_labels)
    val_dataset = JdDataSet(val_encodings, val_labels)
    test_dataset = JdDataSet(test_encodings, test_labels)

    device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')

    with open(f"./roberta_category_to_id.json", 'r') as f:
        cat_to_id = json.load(f)

    num_labels = len(cat_to_id)
    print(f"NUM_LABELS: {num_labels}")

    model = RobertaForSequenceClassification.from_pretrained("microsoft/codebert-base",num_labels=240)
    model.to(device)
    model.train()

    print_gpu_utilization()

    print(f"Train examples: {len(train_dataset)}")
    print(f"Val examples: {len(val_dataset)}")
    print(f"Test examples: {len(test_dataset)}")

    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, pin_memory=True)
    val_loader = DataLoader(val_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, pin_memory=True)
    test_loader = DataLoader(test_dataset, batch_size=EVAL_BATCH_SIZE, shuffle=False, pin_memory=True)

    optim = AdamW(model.parameters(), lr=LEARNING_RATE)

    precision_metrics = torchmetrics.Precision(average='macro',num_classes=240)
    accuracy_metrics = torchmetrics.Accuracy(average='macro',num_classes=240)
    recall_metrics = torchmetrics.Recall(average='macro',num_classes=240)
    f1_metrics = torchmetrics.F1Score(average='macro',num_classes=240)

    total_loss = 0
    final_save_location = 0
    for idx, batch in enumerate(cycle(train_loader)):
        if idx % LOG_INTERVAL == 0:
            print(f"Loss at step {idx}: {total_loss / LOG_INTERVAL}")
            wandb.log({"train": {"loss": total_loss / LOG_INTERVAL}}, commit=True)
            total_loss = 0
            total_correct = 0
            torch.no_grad()
            model.eval()

            print("Validation Loop")
            for val_batch in val_loader:
                input_ids = val_batch['input_ids'].to(device)
                attention_mask = val_batch['attention_mask'].to(device)
                labels = val_batch['labels'].to(device)
                outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
                loss = outputs[0]
                logits = outputs[1]
                print(logits.shape)
                n_logits = logits.detach().cpu()
                labels = labels.detach().cpu()
                precision_metrics.update(n_logits, labels)
                accuracy_metrics.update(n_logits, labels)
                recall_metrics.update(n_logits, labels)
                f1_metrics.update(n_logits, labels)
            
            metrics_dict = {"val": {"acc": accuracy_metrics.compute(), "prec": precision_metrics.compute(), "recall": recall_metrics.compute(), "f1": f1_metrics.compute()}}
            print(metrics_dict)
            wandb.log(metrics_dict, commit=True)
            accuracy_metrics.reset()
            precision_metrics.reset()
            recall_metrics.reset()
            f1_metrics.reset()

            # torch.save(model.state_dict(), f"./model_saves/model_at_batch_{idx}.pt")

        model.train()
        torch.enable_grad()
        optim.zero_grad()
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs[0]
        logits = outputs[1]
        total_loss += loss.item()
        loss.backward()
        optim.step()

    final_total_correct = 0
    model.load_state_dict(torch.load(f"./model_saves/model_at_batch_{final_save_location}.pt"))
    model.eval()

    for batch in test_loader:
        input_ids = batch['input_ids'].to(device)
        attention_mask = batch['attention_mask'].to(device)
        labels = batch['labels'].to(device)
        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)
        loss = outputs[0]
        logits = outputs[1]
        n_logits = logits.detach().cpu().numpy()
        max_indexes = np.argmax(n_logits, axis=1)
        final_total_correct += sum(np.equal(max_indexes, labels.detach().cpu().numpy()) * 1)
    
    print("Accuracy: ", final_total_correct/len(test_dataset))

    
